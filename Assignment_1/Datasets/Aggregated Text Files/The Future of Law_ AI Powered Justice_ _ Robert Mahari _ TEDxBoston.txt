 Now, humanity has reimagined lots of big sectors through computation, through AI, through digital tools, and those include finance, where we've enabled global markets and nearly instantaneous payments, farming where we've reimagined how to produce food for billions of people, medicine where we've figured out breakthroughs that allow us to live longer than ever before, but not law. Lots of days fundamentally the same as it was 100 years ago. The most disruptive technology in the law is probably Microsoft Word. And so everyone's been left behind, even in the United States 90% of the civil problems encountered by low-income Americans receive either no legal aid or insufficient legal aid. Around the world the problem is much worse. And so it is for us to figure out how can we use technology to improve the law. My group at MIT is doing just that and I want to share a couple of examples of the work we're doing. We're thinking about preparing for litigation, scouring hundreds of thousands of legal opinions to identify the most successful strategies for litigation. We've built tools that allow you to input a legal argument and receive sentences from precedent that support that argument. And this kind of AI-enabled co-counsel is not only useful from the perspective of corporate defense attorneys, but also for the overworked and underpaid public defenders that are literally representing millions of people. We think about forecasting legal risk using our models to determine the outcome of lawsuits in the future, quantifying that risk and allowing people to ensure against it, and empowering judicial reform, surfacing the biases in our legal systems, and allowing us to produce the quantitative evidence we need to spearhead reform. We found, for example, that there's so much pervasive bias that you can figure out the outcome of many legal cases without looking at the facts at all, just by knowing information about the judge. AI has risks and there are lots that have been discussed today and elsewhere, like bias, lack of explainability, but there are some interesting risks that are unique to the law. There's this idea of capture by big players. Who's going to develop the legal AI tools? Is it going to be the institutions with existing deep pockets, with technical resources? Are they going to design open tools, or will they be proprietary? We worry about legal ossification. The idea that AI, as a fundamentally backward looking technology, will embed the status quo. We'll make it harder for a lot to change for the better. And finally, the idea of undermining trust. Will people trust AI to advocate for them? Will people trust AI to judge them? And does the mere presence of AI in legal systems undermine trust in the rule of law? There's no doubt in my mind that eventually law will embrace technology. The question is, will it do so in a way that harnesses the benefits while guarding against the dystopian risks? My mission as an engineer and as a lawyer is not only to build the technologies of the future of law, but also to train people on how to use them responsibly, to bring together the educators, the innovators, the business leaders, the community leaders, to think about the responsible deployment of legal AI. And ultimately, to build towards a vision of computational justice, where we enable justice for everyone, not justice as a luxury product, where we enable efficient justice because justice delayed is justice denied, and where we enabled blind justice. Because the outcome of your legal cases should not depend on who was appointed to preside over your case or who is representing you. So if you'd like to find out more, please don't hesitate to contact me. If you'd like to support this mission, reach out. Thank you so much for your time.