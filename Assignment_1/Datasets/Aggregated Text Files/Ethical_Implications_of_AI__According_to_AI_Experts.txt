 I think that one of the mistakes that happens in some of the discourse by over-rotating on the science fiction fears of AI essentially throws in a shadow the two important things to track. One of them in your question, which is the hands of AI in the hands of bad humans, exeterists, rogue states, criminals, etc. Those are substantive and real issues because it is I think a human amplifier and human amplifier of bad people too. There's a set of things to navigate there. And I think the problem with the science fiction discourse, you know, it's going to be super intelligence and the humanities we know and blah, blah, blah, blah. Is that the bad actor worry is much more real, much more present, much even before any science fiction worry and it occludes that discussion. And most of those folks don't really realize that, you know, human beings are pretty terrible things and you should be careful about the human beings enabled to do that. The second part of it, which was what Kevin was going to, is also there is this more implicit thing. Like I actually think one of the things that we're going to see that's going to become more and more important is to say, okay, well, how do we have a sense of what these technological systems are doing as they become more impactful? Another system is one of the key ones that's already out there. But as we begin to have agents that shape how we navigate things, like how we learn something, educate something, deal with something with health, tell stories, what's the basis, what's the theory of the human good that it's operating on and how it interacts with me and we're going to have to get a better language about that and better kind of disclosure of it. I actually think we're okay so far in how all of that's playing out. But as they get better and better, we're going to have to understand that better and that's going to have to be part of the discourse about how we're operating.